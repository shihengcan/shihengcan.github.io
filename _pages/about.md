---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


--<font color=red>Building...</font>

# üìñ About Me
Hengcan Shi (Áü≥ÊÅíÁí®) is a Professor at *the School of Artificial Intelligence and Robotics*, *Hunan University*. Before that, he was an Associate Professor at *the College of Electrical and Information Engineering*, *Hunan University*, a Research Fellow at *the Department of Data Science & AI*, *Monash University*, and a Senior Researcher at *Tencent*. He received his Ph.D. degree in computer vision from *University of Electronic Science and Technology of China* in 2019. He has served as reviewer for *IEEE TPAMI*, *IJCV*, *IEEE TIP*, *TMM*, *TCSVT*, *TIE*, *PR* and *ISPRS*. He was the Web Chair, Area Chair and PC member of *ACMMM*, *CVPR*, *ICCV*, *ECCV*, *AAAI*, *IJCAI*, *ICML*, *ICLR* and *NeurIPS*.

His research interests include Large Model, Image Segmentation/Detection, Vision+Language, and Affective Computing. 


# üî• News
- *2025.12*: &nbsp;üéâüéâ One paper has accepted by IEEE TCSVT. 
- *2025.11*: &nbsp;üéâüéâ Best paper award in IEEE AIHCIR 2025. 

# üìù Selected Publications 
## Datasets and Benchmarks
---
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACMMM 2025</div><img src='images/2025_ACMMM_NaME.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**NaME: A Natural Micro-expression Dataset for Micro-expression Recognition in the Wild**](https://dl.acm.org/doi/pdf/10.1145/3746027.3755095)

Jiateng Liu, **Hengcan Shi**, Haiwen Liang, Xiaolin Xu, Yuan Zong, Yaonan Wang, Wenming Zheng  

ACMMM 2025, [Project](https://github.com/real-ljt/NAMEdataset)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/2024_CVPR_JRDB_Panoptic.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**JRDB-PanoTrack: An Open-world Panoptic Segmentation and Tracking Robotic Dataset in Crowded Human Environments**](https://openaccess.thecvf.com/content/CVPR2024/html/Le_JRDB-PanoTrack_An_Open-world_Panoptic_Segmentation_and_Tracking_Robotic_Dataset_in_CVPR_2024_paper.html)

Duy-Tho Le, Chenhui Gou, Stavya Datta, **Hengcan Shi**, Ian Reid, Jianfei Cai, Hamid Rezatofighi     

CVPR 2024, [Project](https://jrdb.erc.monash.edu/)
</div>
</div>


## Algorithms
---
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCV 2025</div><img src='images/2025_IJCV_LLMFormer.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**LLMFormer: Large LanguageModel for Open-Vocabulary Semantic Segmentation**](https://link.springer.com/article/10.1007/s11263-024-02171-y)

**Hengcan Shi**, Son Duy Dao, Jianfei Cai

IJCV 2025
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/2025_CVPR_DrVideo.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Drvideo: Document retrieval based long video understandings**](https://openaccess.thecvf.com/content/CVPR2025/html/Ma_DrVideo_Document_Retrieval_Based_Long_Video_Understanding_CVPR_2025_paper.html)

Ziyu Ma, Chenhui Gou, **Hengcan Shi**, Bin Sun, Shutao Li, Hamid Rezatofighi, Jianfei Cai  

CVPR 2025
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MICCAI 2025</div><img src='images/2025_MICCAI_CIB.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**New Multiple Sclerosis Lesion Segmentation via Calibrated Inter-patch Blending**](https://papers.miccai.org/miccai-2025/paper/0702_paper.pdf)

Jin Ye, Son Duy Dao, Yicheng Wu, Yasmeen George, Thanh Nguyen-Duc, Daniel F Schmidt, **Hengcan Shi**, Winston Chong, Jianfei Cai  

MICCAI 2025
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='images/2024_ECCV_DifFUSER.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Diffusion Model for Robust Multi-Sensor Fusion in 3D Object Detection and BEV Segmentation**](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08562.pdf)

Duy-Tho Le, **Hengcan Shi**, Jianfei Cai, Hamid Rezatofighi   

ECCV 2024
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2024</div><img src='images/2024_TMM_UOVN.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Unified open-vocabulary dense visual prediction**](https://ieeexplore.ieee.org/abstract/document/10480273)

**Hengcan Shi**, Munawar Hayat, Jianfei Cai  

IEEE TMM 2024
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM TOMM 2024</div><img src='images/2024_ACMTOMM_Bin.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Learning offset probability distribution for accurate object detection**](https://dl.acm.org/doi/pdf/10.1145/3637214)

Heqian Qiu, Hongliang Li, Qingbo Wu, **Hengcan Shi**, Lanxiao Wang, Fanman Meng, Linfeng Xu

ACM TOMM 2024
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/2023_CVPR_TSG.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Transformer scale gate for semantic segmentation**](https://openaccess.thecvf.com/content/CVPR2023/html/Shi_Transformer_Scale_Gate_for_Semantic_Segmentation_CVPR_2023_paper.html)

**Hengcan Shi**, Munawar Hayat, Jianfei Cai  

CVPR 2023
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACMMM 2023</div><img src='images/2023_ACMMM_SGDN.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Open-vocabulary object detection via scene graph discovery**](https://dl.acm.org/doi/pdf/10.1145/3581783.3612407)

**Hengcan Shi**, Munawar Hayat, Jianfei Cai  

ACMMM 2023
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2023</div><img src='images/2023_TMM_CEL.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Class Enhancement Losses with Pseudo Labels for Open-Vocabulary Semantic Segmentation**](https://ieeexplore.ieee.org/abstract/document/10306291/)

Son D Dao, **Hengcan Shi**, Dinh Phung, Jianfei Cai

IEEE TMM 2023
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neurocomputing 2023</div><img src='images/2023_Neurocomputing.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Unpaired referring expression grounding via bidirectional cross-modal matching**](https://www.sciencedirect.com/science/article/abs/pii/S0925231222013686)

**Hengcan Shi**, Munawar Hayat, Jianfei Cai  

Neurocomputing 2023
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MICCAI 2023</div><img src='images/2023_MICCAI_CoactSeg.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Coactseg: Learning from heterogeneous data for new multiple sclerosis lesion segmentation**](https://arxiv.org/pdf/2307.04513)

Yicheng Wu, Zhonghua Wu, **Hengcan Shi**, Bjoern Picker, Winston Chong, Jianfei Cai 

MICCAI 2023
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022</div><img src='images/2022_CVPR_ProposalCLIP.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Proposalclip: Unsupervised open-category object proposal generation via exploiting clip cues**](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_ProposalCLIP_Unsupervised_Open-Category_Object_Proposal_Generation_via_Exploiting_CLIP_Cues_CVPR_2022_paper.html)

**Hengcan Shi**, Munawar Hayat, Yicheng Wu, Jianfei Cai 

CVPR 2022
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RA-L 2022</div><img src='images/2022_RAL_PiFeNet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Accurate and real-time 3D pedestrian detection using an efficient attentive pillar network**](https://arxiv.org/pdf/2112.15458)

Duy Tho Le, **Hengcan Shi**, Hamid Rezatofighi, Jianfei Cai 

IEEE RA-L 2022
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR 2021</div><img src='images/2021_SIGIR_MRCMV.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Deep music retrieval for fine-grained videos by exploiting cross-modal-encoded voice-overs**](https://dl.acm.org/doi/pdf/10.1145/3404835.3462993)

Tingtian Li, Zixun Sun, Haoruo Zhang, Jin Li, Ziming Wu, Hui Zhan, Yipeng Yu, **Hengcan Shi**  

SIGIR 2021
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2020</div><img src='images/2020_CVPR_Bin.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Offset bin classification network for accurate object detection**](https://openaccess.thecvf.com/content_CVPR_2020/html/Qiu_Offset_Bin_Classification_Network_for_Accurate_Object_Detection_CVPR_2020_paper.html)

Heqian Qiu, Hongliang Li, Qingbo Wu, **Hengcan Shi** 

CVPR 2020
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACMMM 2020</div><img src='images/2020_ACMMM_HRRN.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Language-aware fine-grained object representation for referring expression comprehension**](https://dl.acm.org/doi/pdf/10.1145/3394171.3413850)

Heqian Qiu, Hongliang Li, Qingbo Wu, Fanman Meng, **Hengcan Shi**, Taijin Zhao, King Ngi Ngan

ACMMM 2020
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2020</div><img src='images/2020_TMM_QRN.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Query reconstruction network for referring expression image segmentation**](https://ieeexplore.ieee.org/abstract/document/9082867)

**Hengcan Shi**, Hongliang Li, Qingbo Wu, King Ngi Ngan

IEEE TMM 2020
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2020</div><img src='images/2020_TMM_HCE.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Hierarchical context features embedding for object detection**](https://ieeexplore.ieee.org/abstract/document/8979187)

Heqian Qiu, Hongliang Li, Qingbo Wu, Fanman Meng, Linfeng Xu, King Ngi Ngan, **Hengcan Shi**

IEEE TMM 2020
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2019</div><img src='images/2019_CVPR_ICM.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Scene Parsing via Integrated Classification Model and Variance-Based Regularization**](https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Scene_Parsing_via_Integrated_Classification_Model_and_Variance-Based_Regularization_CVPR_2019_paper.html)

**Hengcan Shi**, Hongliang Li, Qingbo Wu, Zichen Song

CVPR 2019
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Remote Sensing 2019</div><img src='images/2019_Remote_A2RMNet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**A2RMNet: Adaptively Aspect Ratio Multi-Scale Network for Object Detection in Remote Sensing Images**](https://www.mdpi.com/2072-4292/11/13/1594)

Heqian Qiu, Hongliang Li, Qingbo Wu, Fanman Meng, King Ngi Ngan, **Hengcan Shi**

Remote Sensing 2019
</div>
</div>


# üéñ Selected Honors and Awards
- *2025*: Distinguished Breakthrough Award in ACMMM 2025 AVI Challenge
- *2025*: Best paper Award in IEEE AIHCIR 2025
- *2021*: Excellent Doctoral Dissertation Award in CSIG
- *2019*: The First Price in NSFC Remote Sensing Image Segmentation Challenge